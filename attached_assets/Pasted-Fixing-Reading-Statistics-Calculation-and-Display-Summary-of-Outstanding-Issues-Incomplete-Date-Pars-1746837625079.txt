Fixing Reading Statistics Calculation and Display
Summary of Outstanding Issues
Incomplete Date Parsing: The Day.js date parsing logic was added (in utils/goodreadsParser.js) but not actually used in the upload flow. The server’s parseGoodreadsCsv function still uses new Date on raw strings (or wasn’t converting at all), leading to incorrect or missing dates. As a result, books read dates were not parsed properly, causing the “Books This Year” and “Books per Month” counts to be wrong (often zero because the year/month weren’t recognized).
Type Mismatches in Stats: The backend generateStats function expects book.dateRead as a Date object and numeric fields as numbers. However, without proper parsing, dateRead remained a string or null and rating/page fields were strings. This caused calculations like readingByYear and averageRating to fail silently or produce NaN (e.g. dividing by zero length). The “Average Rating” could show as 0 or blank due to NaN not being handled.
Inconsistent Stats Data Structure: Some important fields were missing or placed differently between backend and frontend. For example, totalPages was computed on the backend but not included in the frontend’s calculated stats, causing the “Pages Read” stat to display 0. The backend’s readingPace used keys (currentYear, etc.) that the frontend didn’t use, while the frontend expected booksPerMonth, etc. Similarly, pageStats (average length, longest book) was only computed on the frontend. These inconsistencies meant the frontend wasn’t properly showing those stats when using backend data.
Frontend Integration Issues: The frontend was always recalculating stats and not using the backend’s stats object. Moreover, the server’s response structure changed to nest books and stats under a data field, but processReadingData in the context wasn’t updated to handle this object. This led to processReadingData treating the entire object as an array (due to a falsy length), immediately returning without updating stats. The consequence was that after upload, the app state didn’t actually get the new stats or book data, leaving stats displays empty or stuck at defaults.
Step-by-Step Fix Implementation
To resolve these issues, we need to update both the backend and frontend for proper parsing, calculation, and data flow:
Improve CSV Parsing on Backend: Open server.js. Find the definition of parseGoodreadsCsv (the function that reads the uploaded file). Update it to transform the CSV rows into book objects with correctly typed fields:
Use Day.js to parse the date strings into JavaScript Date objects. Add a helper (or inline) to try multiple formats ("YYYY/MM/DD", "MM/DD/YYYY", "YYYY-MM-DD", "DD/MM/YYYY") so that dates are reliably parsed. For example:
js
Copy
Edit
const parseDateStr = (dateStr) => {
  if (!dateStr || !dateStr.trim()) return null;
  const parsed = dayjs(dateStr.trim(), [
    'YYYY/MM/DD', 'MM/DD/YYYY', 'YYYY-MM-DD', 'DD/MM/YYYY'
  ]);
  return parsed.isValid() ? parsed.toDate() : null;
};
In the CSV stream’s on('data', ...) callback, replace the simple push of row with creation of a book object. Only include books where the Exclusive Shelf is "read" (this filter exists already). Set each field on book with proper types:
js
Copy
Edit
const book = {
  bookId: row['Book Id'] || '',
  title: row['Title'] || '',
  author: row['Author'] || '',
  authorLastFirst: row['Author l-f'] || '',
  additionalAuthors: row['Additional Authors'] || '',
  isbn: row['ISBN'] || '',
  isbn13: row['ISBN13'] || '',
  exclusiveShelf: row['Exclusive Shelf'] || '',
  myRating: parseInt(row['My Rating']) || 0,
  averageRating: parseFloat(row['Average Rating']) || 0,
  pages: parseInt(row['Number of Pages']) || 0,
  yearPublished: parseInt(row['Year Published']) || null,
  originalPublicationYear: parseInt(row['Original Publication Year']) || null,
  readCount: parseInt(row['Read Count']) || 0,
  ownedCopies: parseInt(row['Owned Copies']) || 0,
  dateRead: parseDateStr(row['Date Read']),    // parsed Date or null
  dateAdded: parseDateStr(row['Date Added']) || null,
  bookshelves: row['Bookshelves'] || '',
  bookshelvesWithPositions: row['Bookshelves with positions'] || '',
  myReview: row['My Review'] || '',
  spoiler: row['Spoiler'] || '',
  privateNotes: row['Private Notes'] || ''
};
if (book.exclusiveShelf === 'read') {
  // Push all read books, even if dateRead is null (we’ll handle missing dates in stats)
  books.push(book);
}
This ensures every book in books has dateRead as a Date (or null) and numeric fields as actual numbers. The Day.js plugin customParseFormat is already initialized at the top of the file, so the parsing will work for the common date formats.
Use the Updated Parser Everywhere: Still in server.js, find where parseGoodreadsCsv is called in the upload route and any other place.
In the app.post('/api/upload', ...) handler, it already calls parseGoodreadsCsv(req.file.path). With the above changes, this will now return fully parsed book objects. No further changes needed in that line aside from ensuring it awaits correctly (which it does).
Also check for usage of parseGoodreadsCSV (capital C) from the utils. In the latest code, there is an endpoint (likely a stats retrieval for the most recent file) that does:
js
Copy
Edit
const results = await parseGoodreadsCSV(...);
return res.json({ success: true, stats: generateStats(results), data: results });
Since we have improved the internal parseGoodreadsCsv, we should use it here as well (and the utils version might not be imported at all). Replace parseGoodreadsCSV with our parseGoodreadsCsv in that endpoint. For example:
js
Copy
Edit
const results = await parseGoodreadsCsv(path.join(uploadDir, mostRecentFile));
return res.json({ success: true, stats: generateStats(results), data: results });
This ensures the same parsing logic is used consistently.
Fix Stats Aggregation on Backend: Next, update the generateStats function in server.js to properly calculate all required statistics and ensure the structure matches what the frontend expects. Key fixes:
Avoid NaN for Average Rating: Calculate averageRating using only books with a rating. For example:
js
Copy
Edit
const ratedBooks = books.filter(b => b.myRating && b.myRating > 0);
const averageRating = ratedBooks.length 
  ? ratedBooks.reduce((sum, b) => sum + b.myRating, 0) / ratedBooks.length 
  : 0;
This way, if no books have a personal rating, averageRating will be 0 (instead of NaN). You can round or format it later when displaying; storing as a precise float is fine (e.g., keep a couple of decimal places).
Complete readingByYear and readingByMonth: The existing logic to accumulate counts by year and by month is fine assuming dateRead is a Date. Our parser provides Date objects (or null). It already skips books with no dateRead (if (book.dateRead) {...}). This will correctly compute the “Books This Year” (as readingByYear[currentYear]). No change needed here besides the parser fix we did.
Include Total Pages and Average Pages per Book: Ensure totalPages is calculated (it is) and then use it to compute average pages per book (this is essentially the average book length). We can place this in a field the frontend uses. The backend currently returns averagePagesPerBook but the frontend expects pageStats.averageLength. Let’s populate both to be safe:
js
Copy
Edit
const totalPages = books.reduce((sum, b) => sum + (b.pages || 0), 0);
const avgPages = books.length ? Math.round(totalPages / books.length) : 0;
We will use avgPages for both a top-level averagePagesPerBook and within a pageStats object as averageLength.
Determine Longest Book: Identify the book with the maximum page count for the “Longest Book” stat. For example:
js
Copy
Edit
let longestBook = { title: '', pages: 0 };
books.forEach(b => {
  if ((b.pages || 0) > (longestBook.pages || 0)) {
    longestBook = { title: b.title || '(Unknown)', pages: b.pages || 0 };
  }
});
After this, longestBook will have the title and page count of the longest book (or remain at 0 if none).
Simplify Reading Pace: Replace or adjust the readingPace object to include the metrics the dashboard displays. The frontend shows “books per year” and “pages per day” (and also calculates “books per month”). We will provide:
booksPerYear: We can interpret this as total books (if the intention is overall average per year, we’ll use total for simplicity, but if the data spans multiple years, this could be refined). Given the original frontend simply took totalBooks as “books per year,” we’ll do the same.
booksPerMonth: Average books per month. To be more accurate, we can use the helper (averageBooksPerMonth) which calculates based on active years, but the UI expected a single number. We can directly compute a monthly average: e.g. booksPerMonth = parseFloat((books.length / 12).toFixed(2)) as a rough yearly average, or use the provided helper result.
pagesPerDay: average pages per day, which we can compute as totalPages / 365 (again, assuming one year’s scale; if data spans years this is more like pages per day over those years, but we’ll keep it simple unless we want to refine it).
js
Copy
Edit
const readingPace = {
  booksPerYear: books.length,
  booksPerMonth: parseFloat((books.length / 12).toFixed(2)),
  pagesPerDay: parseFloat((totalPages / 365).toFixed(2))
};
(If you prefer to use the more accurate calculateAverageBooksPerMonth(books) from the helper, use that for booksPerMonth. Either will give a reasonable value.)
Assemble the Stats Object: Now return an object containing all these fields. Ensure it has at least the following keys that the frontend expects:
js
Copy
Edit
return {
  totalBooks: books.length,
  totalPages: totalPages,
  averageRating: parseFloat(averageRating.toFixed(2)),  // e.g., keep two decimals
  readingByYear,
  readingByMonth,
  readingByGenre: {},        // (Optional) compute from bookshelves if needed; empty is okay for now
  topAuthors,               // already an array of { author, count }
  ratingDistribution,       // the object with star counts (1-5)
  readingPace,
  pageStats: {
    averageLength: avgPages,
    longestBook: longestBook
  }
  // (You can include averagePagesPerBook: avgPages as well, for consistency with any other usage)
};
Also handle the case of no books by returning an empty stats object with all the above keys set to default values (zeros and empty objects/arrays). Currently, generateStats returns a partial object on empty input. Let’s return a complete structure:
js
Copy
Edit
if (!books || books.length === 0) {
  return {
    totalBooks: 0,
    totalPages: 0,
    averageRating: 0,
    readingByYear: {},
    readingByMonth: {},
    readingByGenre: {},
    topAuthors: [],
    ratingDistribution: {1:0, 2:0, 3:0, 4:0, 5:0},
    readingPace: { booksPerYear: 0, booksPerMonth: 0, pagesPerDay: 0 },
    pageStats: { averageLength: 0, longestBook: { title: '', pages: 0 } }
  };
}
This ensures the frontend won’t encounter undefined fields even if no data is present.
Adjust Server Response Structure (if needed): In the upload route response (res.json in the /api/upload handler), make sure we properly send both books and stats. The current code nests them under data. It returns like:
js
Copy
Edit
return res.json({ data: { books, stats } });
This is fine, but we must ensure the frontend knows how to handle it. We will update the frontend accordingly in the next step. (Alternatively, you could flatten it to { books, stats } at the top level. Here, we’ll keep the nested structure and adjust the frontend parser.)
Use Backend Stats on Frontend: Open client/src/context/ReadingDataContext.js. We will modify the processReadingData function to utilize the stats from the backend instead of always recalculating. This will also fix the issue where the nested response wasn’t being handled. Do the following in processReadingData:
At the start of the function, detect if the incoming data is the object containing both books and stats. For example:
js
Copy
Edit
const processReadingData = (data) => {
  setLoading(true);
  try {
    // If data contains books and stats (as from backend response)
    if (data && !Array.isArray(data) && data.books && data.stats) {
      const books = data.books;
      const statsObj = data.stats;
      setReadingData(books);
      setStats(statsObj);
      // Update goal progress based on the new books list
      const goalsObj = calculateGoalProgress(books);
      setGoalProgress(goalsObj);
      // Save all to local storage
      storageService.saveData({ readingData: books, stats: statsObj, goalProgress: goalsObj });
      setLoading(false);
      return;  // done
    }
    // ... (existing logic for when data is just an array) ...
  } catch (err) {
    setError(err.message);
  } finally {
    setLoading(false);
  }
};
This branch checks if data is not an array and has the expected properties (books and stats). In that case, it uses the provided stats directly: setting readingData to the books array and stats state to the stats object from the server. We still call calculateGoalProgress with the books to update the goals (this uses the current year/month counts, which should now be accurate thanks to parsed dates). We then save the new state to local storage and return early, skipping the old manual stats calculation.
Keep the original logic in the else (or below the if) to handle scenarios where data might still be just an array (for example, if we ever call processReadingData with only an array of books). This ensures backward compatibility, but after an upload, we’ll be passing the combined object.
With this change, when the upload response is received in FileUpload.js, we do processReadingData(response.data.data). Now response.data.data contains { books, stats }, so our new branch will run. The state will get updated with parsed books and precomputed stats directly.
Frontend Defensive Fixes: While the above covers most issues, let’s tighten a couple of frontend calculations to handle missing data gracefully (especially for any books without a dateRead):
In calculateStats (still in ReadingDataContext.js), add a guard so that books with no dateRead are skipped in the reading-by-year and month calculations. Currently it does:
js
Copy
Edit
books.forEach(book => {
  const year = new Date(book.dateRead).getFullYear().toString();
  const month = new Date(book.dateRead).getMonth();
  // ...
});
Insert at the top of that loop:
js
Copy
Edit
  if (!book.dateRead) return;
This way, if any book has a null or empty dateRead, it won’t produce an invalid year (earlier, new Date(null) would yield 1970, skewing the stats). By skipping, those books still count toward totalBooks and pages, but not towards a specific year/month. (Our backend already does similar by ignoring null dates in year counts.)
Similarly, ensure defensive defaults in the UI remain (the Dashboard and other components already do stats.readingPace = stats.readingPace || {} etc., which is good). With our changes, most of those fields will be present. One thing to double-check is that stats.totalPages is now provided by the backend, so the “Pages Read” stat will display correctly (no longer stuck at 0). We included totalPages in the stats object, so <p>{(stats.totalPages || 0).toLocaleString()} total pages</p> will show the actual total pages read.
Test the End-to-End Fix:
Re-run the server and upload a Goodreads CSV. The backend should now parse dates properly using Day.js (try a mix of date formats to be sure) and compute stats.
After uploading, the frontend’s context should receive a { books, stats } object. Confirm that processReadingData enters the new branch and sets the context states.
Verify that the Dashboard shows correct values for “Books This Year” (e.g., matches the count of books with dateRead in the current year), “Books per Month” (a reasonable average, not 0 unless truly no data), “Average Rating” (now reflecting the average of your rated books, with one decimal), “Pages Read” (total pages count), “Longest Book” (title and pages of the longest one), etc. Also check that no stat cards are blank or obviously incorrect.
If any stat still looks off, double-check the corresponding field in the stats object and adjust the calculation if needed. All components (YearlyProgress, MonthlyProgress, Goals, etc.) should be receiving the populated stats from context, so they should update accordingly.
By following these steps, we ensure that the Goodreads CSV data is correctly parsed and that the reading statistics are accurately calculated on the backend and seamlessly utilized on the frontend. The stats display should now reflect the true values from the uploaded data, resolving the prior inconsistencies. Good luck!